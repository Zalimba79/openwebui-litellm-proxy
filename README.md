ðŸ‡©ðŸ‡ª Deutsch:
openwebui-litellm-proxy ist ein Setup-Projekt zur Integration von LiteLLM als universelle API-Schnittstelle fÃ¼r verschiedene LLM-Anbieter in OpenWebUI.
Es ermÃ¶glicht die Anbindung von Modellen wie OpenAI, Mistral, Ollama, Anthropic u.â€¯v.â€¯m. Ã¼ber eine zentrale Proxy-Konfiguration.

ðŸ‡¬ðŸ‡§ English:
openwebui-litellm-proxy is a setup project to integrate LiteLLM as a universal API gateway for multiple LLM providers into OpenWebUI.
It enables seamless use of models like OpenAI, Mistral, Ollama, Anthropic, and others via one central proxy configuration.